{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from attack.fast_gradient_method_preprocess import fast_gradient_method\n",
    "from attack.projected_gradient_descent_preprocess import projected_gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/nthudatalab1/Jimmy/RMC/ICML_377_runtime_masking_cleansing/ImageNet'\n",
    "TRAIN_DATA_DIR = '/data/train_path.npy'\n",
    "TRAIN_LABEL_DIR = '/data/train_label.npy'\n",
    "EVAL_DATA_DIR = '/data/eval_path.npy'\n",
    "EVAL_LABEL_DIR = '/data/eval_label.npy'\n",
    "ATTACK_DATA_DIR = ''\n",
    "ATTACK_LABEL_DIR = ''\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "IMG_SIZE = 224\n",
    "RESIZE_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "TARGET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "# Training data\n",
    "train_path = np.load(BASE_DIR + TRAIN_DATA_DIR)\n",
    "train_label = np.load(BASE_DIR + TRAIN_LABEL_DIR)\n",
    "assert len(train_path) == len(train_label)\n",
    "\n",
    "# Evaluation data\n",
    "eval_path = np.load(BASE_DIR + EVAL_DATA_DIR)\n",
    "eval_label = np.load(BASE_DIR + EVAL_LABEL_DIR)\n",
    "assert len(eval_path) == len(eval_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _training_data_generator(image_path, label):\n",
    "    # Read image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    \n",
    "    # Resize\n",
    "    img = tf.image.resize(img, size=[RESIZE_SIZE, RESIZE_SIZE])\n",
    "    img = tf.image.random_crop(img, size=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    # Augmentation\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.4)\n",
    "    img = tf.image.random_contrast(img, lower=0.6, upper=1.4)\n",
    "    img = tf.image.random_saturation(img, lower=0.6, upper=1.4)\n",
    "    return img, label\n",
    "\n",
    "def _testing_data_generator(image_path, label):\n",
    "    # Read image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = scale19(img)\n",
    "    return img, label\n",
    "\n",
    "def _attacking_data_generator(image_path, label):\n",
    "    # Read image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def _target_data_generator(image_path, label, target_label):\n",
    "    # Read image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = scale19(img)\n",
    "    return img, label, target_label\n",
    "\n",
    "def training_dataset_generator(img_path, label, batch_size):\n",
    "    assert img_path.shape[0] == label.shape[0]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_path, label))\n",
    "    dataset = dataset.map(_training_data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def testing_dataset_generator(img_path, label, dataset_generator, batch_size):\n",
    "    assert img_path.shape[0] == label.shape[0]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_path, label))\n",
    "    dataset = dataset.map(dataset_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def target_dataset_generator(img_path, label, target_label, dataset_generator, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_path, label, target_label))\n",
    "    dataset = dataset.map(dataset_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, shape=(224,224)):\n",
    "    target_width = shape[0]\n",
    "    target_height = shape[1]\n",
    "    initial_width = tf.shape(image)[0]\n",
    "    initial_height = tf.shape(image)[1]\n",
    "    im = image\n",
    "    ratio = 0\n",
    "    if(initial_width < initial_height):\n",
    "        ratio = tf.cast(256 / initial_width, tf.float32)\n",
    "        h = tf.cast(initial_height, tf.float32) * ratio\n",
    "        im = tf.image.resize(im, (256, h), method=\"bicubic\")\n",
    "    else:\n",
    "        ratio = tf.cast(256 / initial_height, tf.float32)\n",
    "        w = tf.cast(initial_width, tf.float32) * ratio\n",
    "        im = tf.image.resize(im, (w, 256), method=\"bicubic\")\n",
    "    width = tf.shape(im)[0]\n",
    "    height = tf.shape(im)[1]\n",
    "    startx = width//2 - (target_width//2)\n",
    "    starty = height//2 - (target_height//2)\n",
    "    im = tf.image.crop_to_bounding_box(im, startx, starty, target_width, target_height)\n",
    "    return im\n",
    "\n",
    "def scale19(image):\n",
    "    i = resize_image(image, (224,224))\n",
    "    return (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random classes as targeted classes in targeted attack\n",
    "if TARGET:\n",
    "    target_label = np.random.randint(1000, size=len(eval_label))\n",
    "    # Remove replicate label\n",
    "    for overlap in np.where(eval_label == target_label)[0]:\n",
    "        new_label = np.random.randint(1000, size=1)\n",
    "        while new_label != eval_label[overlap]:\n",
    "            target_label[overlap] = new_label\n",
    "            new_label = np.random.randint(1000, size=1)\n",
    "    np.save(ATTACK_LABEL_DIR, target_label)\n",
    "    test_ds = target_dataset_generator(eval_path, eval_label, target_label, _target_data_generator, BATCH_SIZE)\n",
    "else:\n",
    "    test_ds = testing_dataset_generator(eval_path, eval_label, _testing_data_generator, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet152V2():\n",
    "    IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "    resnet152v2 = tf.keras.applications.ResNet152V2(include_top=True,\n",
    "                                                    weights='imagenet',\n",
    "                                                    input_shape=IMG_SHAPE, \n",
    "                                                    classes=1000)\n",
    "    return resnet152v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152v2 = ResNet152V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "attack_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='attack_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = resnet152v2(images)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def attack_step(images, labels):\n",
    "    predictions = resnet152v2(images)\n",
    "    attack_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robustness: 3.12%\n",
      "Attack Success Rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# PGD attack(norm=np.inf)\n",
    "epsilons = [0, 8/255, 16/255, 32/255]\n",
    "eps_iters = [1.6/255, 2/255, 1/255]\n",
    "nb_iters = [10, 10, 100]\n",
    "\n",
    "adv_image_list = []\n",
    "# Targeted attack\n",
    "if TARGET:\n",
    "    for images, labels, target_labels in test_ds:\n",
    "        adv_images = projected_gradient_descent(model_fn=resnet152v2, \n",
    "                                                model_preprocess=tf.keras.applications.resnet_v2.preprocess_input, \n",
    "                                                x=images,\n",
    "                                                eps=epsilons[2], \n",
    "                                                eps_iter=eps_iters[2], \n",
    "                                                nb_iter=nb_iters[2], \n",
    "                                                norm=np.inf,\n",
    "                                                clip_min=None, \n",
    "                                                clip_max=None, \n",
    "                                                y=target_labels, \n",
    "                                                targeted=True,\n",
    "                                                rand_init=True, \n",
    "                                                rand_minmax=0.3,\n",
    "                                                sanity_checks=True)\n",
    "        adv_image_list.append(adv_images.numpy())\n",
    "\n",
    "        # Evaluate robustness and attack success rate\n",
    "        _adv_images = tf.keras.applications.resnet_v2.preprocess_input(adv_images*255)\n",
    "        test_step(_adv_images, labels)\n",
    "        attack_step(_adv_images, target_labels)\n",
    "        break\n",
    "# Non-targeted attack\n",
    "else:\n",
    "    for images, labels in test_ds:\n",
    "        adv_images = projected_gradient_descent(model_fn=resnet152v2, \n",
    "                                                model_preprocess=tf.keras.applications.resnet_v2.preprocess_input, \n",
    "                                                x=images,\n",
    "                                                eps=epsilons[2], \n",
    "                                                eps_iter=eps_iters[2], \n",
    "                                                nb_iter=nb_iters[2], \n",
    "                                                norm=np.inf,\n",
    "                                                clip_min=None, \n",
    "                                                clip_max=None, \n",
    "                                                y=labels, \n",
    "                                                targeted=False,\n",
    "                                                rand_init=True, \n",
    "                                                rand_minmax=0.3,\n",
    "                                                sanity_checks=True)\n",
    "        adv_image_list.append(adv_images.numpy())\n",
    "\n",
    "        # Evaluate robustness\n",
    "        _adv_images = tf.keras.applications.resnet_v2.preprocess_input(adv_images*255)\n",
    "        test_step(_adv_images, labels)\n",
    "        break\n",
    "    \n",
    "print(\"Robustness: {:.2f}%\".format(test_accuracy.result()*100))\n",
    "print(\"Attack Success Rate: {:.2f}%\".format(attack_accuracy.result()*100))\n",
    "test_accuracy.reset_states()\n",
    "attack_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_image_list = np.asarray(adv_image_list)\n",
    "adv_images = np.vstack(adv_image_list)\n",
    "\n",
    "# Save adversarial examples in single numpy file\n",
    "np.save(ATTACK_DATA_DIR, adv_images)\n",
    "\n",
    "# Save adversarial examples in seperate numpy file\n",
    "for adv_image, adv_path in zip(adv_images, eval_path):\n",
    "    np.save(adv_path.replace('val_set', ATTACK_DATA_DIR).replace('JPEG', 'npy'), adv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
